- [Lab 3: A simple lexer](#org5cfc323)
- [Theory](#org74327b2)
  - [Lexical analysis](#org732ae06)
- [Objectives](#org5545cea)
- [Results](#org923194d)
- [Implementation](#orgc2bc5f8)




<a id="org5cfc323"></a>

# Lab 3: A simple lexer

Course
: Formal Languages &amp; Finite Automata

Author
: Prodan Denis


<a id="org74327b2"></a>

# Theory


<a id="org732ae06"></a>

## Lexical analysis

Lexical analysis, also known as tokenization, is the process of converting a sequence of characters into a sequence of tokens (meaningful units) in order to facilitate the analysis of a text or program. The tokens can be thought of as the basic building blocks of a language, and are typically classified into different categories such as identifiers, keywords, literals, operators, and punctuation symbols.

The main goal of lexical analysis is to identify and group these tokens based on their semantic meaning, and to provide a structured representation of the input text that can be easily processed by subsequent stages of a compiler or interpreter. This process involves several steps, such as removing whitespace and comments, identifying and classifying tokens, and recording information about each token such as its location in the source code and any associated metadata.

Lexical analysis is a crucial component of most programming languages and is typically the first step in the compilation or interpretation process. It is also used in natural language processing to analyze and understand the meaning of text.

<a id="org5545cea"></a>

# Objectives

-   [X] Implement a lexer and show how it works.


<a id="org923194d"></a>

# Results

I wrote a lexer for python-like syntax plus some elements of c language, hence, all the example strings are valid python code.

This example contains everything that my language has. Every line of code should end with semicolon therefore we can stack everything into one line.
Functions and if statements content should be contained in open and closed curly brackets. Everything else is syntax like python.

```text
a = 4 + (c + 6) / 3.213;
b = 5;
def fdasd(a, b){
    return True;
}
if f(a, b) and b==1 or c >= 1{
    print("hello world"); }
```

This is how my source code has been tokenized
```text
TokenType.NAME:a
TokenType.ASSIGMENT:=
TokenType.NUMBER:4
TokenType.PLUS:+
TokenType.LPAREN:(
TokenType.NAME:c
TokenType.PLUS:+
TokenType.NUMBER:6
TokenType.RPAREN:)
TokenType.DIV:/
TokenType.NUMBER:3.213
TokenType.ENDOFLINE:;
TokenType.NAME:b
TokenType.ASSIGMENT:=
TokenType.NUMBER:5
TokenType.ENDOFLINE:;
TokenType.FUNDEF:def
TokenType.NAME:fdasd
TokenType.LPAREN:(
TokenType.NAME:a
TokenType.COMMA:,
TokenType.COMPARISONOP:==
TokenType.NUMBER:1
TokenType.LOGICOP:or
TokenType.NAME:c
TokenType.COMPARISONOP:>=
TokenType.NUMBER:1
TokenType.START:{
TokenType.NAME:print
TokenType.LPAREN:(
TokenType.STRING:hello world
TokenType.RPAREN:)
TokenType.ENDOFLINE:;
TokenType.END:}
```


<a id="orgc2bc5f8"></a>

# Implementation

This code implements a lexer, which is a program that takes source code as input and breaks it down into a sequence of tokens that can be processed by a parser. The lexer is implemented as a Python class called Lexer, which takes a string of source code as input when it is initialized.

The Lexer class has several methods for processing the input string and generating a list of tokens. The getTokens() method is the main entry point for the lexer, and it processes the input string character by character to generate a list of tokens.

The advance() method is used to move the current character pointer to the next character in the input string. The getNumber() method is used to extract a number token from the input string, the getWord() method is used to extract a name token from the input string, and the getString() method is used to extract a string token from the input string.

The TokenType class defines an enumeration of all the possible token types that the lexer can generate, such as NUMBER, PLUS, MINUS, DIV, LPAREN, RPAREN, ASSIGMENT, FUNDEF, ENDOFLINE, COMMA, SEMICOL, STRING, NAME, BOOL, START, END, IF, MULT, LOGICOP, and COMPARISONOP.

The Token class represents a single token generated by the lexer. It has two properties, type and value, which represent the type of the token and its value, respectively.


